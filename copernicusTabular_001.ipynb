{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copernicus Tabular\n",
    "In this notebook we will begin developing Copernicus Framework that deals with **Tabular** Data. This includes: \n",
    "* DataSet Formation\n",
    "* Model Formation\n",
    "\n",
    "## VERSION Alpha: 0.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# dependencies & imports\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from path import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "torch.cuda.set_device(0)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grabbing dummy data\n",
    "path = Path('./data/wids')\n",
    "data = pd.read_csv(path/'train.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>AA3</th>\n",
       "      <th>AA4</th>\n",
       "      <th>AA5</th>\n",
       "      <th>AA6</th>\n",
       "      <th>AA7</th>\n",
       "      <th>AA14</th>\n",
       "      <th>AA15</th>\n",
       "      <th>DG1</th>\n",
       "      <th>is_female</th>\n",
       "      <th>...</th>\n",
       "      <th>GN1</th>\n",
       "      <th>GN1_OTHERS</th>\n",
       "      <th>GN2</th>\n",
       "      <th>GN2_OTHERS</th>\n",
       "      <th>GN3</th>\n",
       "      <th>GN3_OTHERS</th>\n",
       "      <th>GN4</th>\n",
       "      <th>GN4_OTHERS</th>\n",
       "      <th>GN5</th>\n",
       "      <th>GN5_OTHERS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>323011</td>\n",
       "      <td>3854</td>\n",
       "      <td>481</td>\n",
       "      <td>1975</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>268131</td>\n",
       "      <td>2441</td>\n",
       "      <td>344</td>\n",
       "      <td>1981</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>167581</td>\n",
       "      <td>754</td>\n",
       "      <td>143</td>\n",
       "      <td>1995</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>445071</td>\n",
       "      <td>5705</td>\n",
       "      <td>604</td>\n",
       "      <td>1980</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>436161</td>\n",
       "      <td>5645</td>\n",
       "      <td>592</td>\n",
       "      <td>1958</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1235 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id  AA3  AA4  AA5  AA6     AA7  AA14  AA15   DG1  is_female  ...  \\\n",
       "0         0    3   32  3.0  NaN  323011  3854   481  1975          1  ...   \n",
       "1         1    2   26  NaN  8.0  268131  2441   344  1981          1  ...   \n",
       "2         2    1   16  NaN  7.0  167581   754   143  1995          1  ...   \n",
       "3         3    4   44  5.0  NaN  445071  5705   604  1980          1  ...   \n",
       "4         4    4   43  NaN  6.0  436161  5645   592  1958          1  ...   \n",
       "\n",
       "    GN1  GN1_OTHERS GN2  GN2_OTHERS  GN3  GN3_OTHERS  GN4  GN4_OTHERS  GN5  \\\n",
       "0  99.0         NaN  99         NaN   99         NaN   99         NaN   99   \n",
       "1   NaN         NaN   1         NaN    2         NaN    2         NaN    2   \n",
       "2   1.0         NaN   2         NaN    2         NaN    2         NaN    2   \n",
       "3   NaN         NaN   2         NaN    2         NaN   99         NaN   99   \n",
       "4   NaN         NaN   1         NaN    1         NaN    1         NaN    1   \n",
       "\n",
       "   GN5_OTHERS  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  \n",
       "\n",
       "[5 rows x 1235 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AA3</th>\n",
       "      <th>AA4</th>\n",
       "      <th>AA5</th>\n",
       "      <th>AA6</th>\n",
       "      <th>AA7</th>\n",
       "      <th>AA14</th>\n",
       "      <th>AA15</th>\n",
       "      <th>DG1</th>\n",
       "      <th>is_female</th>\n",
       "      <th>DG3</th>\n",
       "      <th>...</th>\n",
       "      <th>GN1</th>\n",
       "      <th>GN1_OTHERS</th>\n",
       "      <th>GN2</th>\n",
       "      <th>GN2_OTHERS</th>\n",
       "      <th>GN3</th>\n",
       "      <th>GN3_OTHERS</th>\n",
       "      <th>GN4</th>\n",
       "      <th>GN4_OTHERS</th>\n",
       "      <th>GN5</th>\n",
       "      <th>GN5_OTHERS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>323011</td>\n",
       "      <td>3854</td>\n",
       "      <td>481</td>\n",
       "      <td>1975</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>268131</td>\n",
       "      <td>2441</td>\n",
       "      <td>344</td>\n",
       "      <td>1981</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 1234 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AA3  AA4  AA5  AA6     AA7  AA14  AA15   DG1  is_female  DG3  ...   GN1  \\\n",
       "0    3   32  3.0  NaN  323011  3854   481  1975          1    3  ...  99.0   \n",
       "1    2   26  NaN  8.0  268131  2441   344  1981          1    8  ...   NaN   \n",
       "\n",
       "  GN1_OTHERS  GN2  GN2_OTHERS  GN3  GN3_OTHERS  GN4  GN4_OTHERS  GN5  \\\n",
       "0        NaN   99         NaN   99         NaN   99         NaN   99   \n",
       "1        NaN    1         NaN    2         NaN    2         NaN    2   \n",
       "\n",
       "   GN5_OTHERS  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "\n",
       "[2 rows x 1234 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing train_id\n",
    "data.drop('train_id', axis=1, inplace=True)\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AA3</th>\n",
       "      <th>AA4</th>\n",
       "      <th>AA5</th>\n",
       "      <th>AA6</th>\n",
       "      <th>AA7</th>\n",
       "      <th>AA14</th>\n",
       "      <th>AA15</th>\n",
       "      <th>DG1</th>\n",
       "      <th>is_female</th>\n",
       "      <th>DG3</th>\n",
       "      <th>...</th>\n",
       "      <th>GN1</th>\n",
       "      <th>GN1_OTHERS</th>\n",
       "      <th>GN2</th>\n",
       "      <th>GN2_OTHERS</th>\n",
       "      <th>GN3</th>\n",
       "      <th>GN3_OTHERS</th>\n",
       "      <th>GN4</th>\n",
       "      <th>GN4_OTHERS</th>\n",
       "      <th>GN5</th>\n",
       "      <th>GN5_OTHERS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>323011</td>\n",
       "      <td>3854</td>\n",
       "      <td>481</td>\n",
       "      <td>1975</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>268131</td>\n",
       "      <td>2441</td>\n",
       "      <td>344</td>\n",
       "      <td>1981</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>167581</td>\n",
       "      <td>754</td>\n",
       "      <td>143</td>\n",
       "      <td>1995</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>445071</td>\n",
       "      <td>5705</td>\n",
       "      <td>604</td>\n",
       "      <td>1980</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>436161</td>\n",
       "      <td>5645</td>\n",
       "      <td>592</td>\n",
       "      <td>1958</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1234 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AA3  AA4  AA5  AA6     AA7  AA14  AA15   DG1  is_female  DG3  ...   GN1  \\\n",
       "0    3   32  3.0  NaN  323011  3854   481  1975          1    3  ...  99.0   \n",
       "1    2   26  NaN  8.0  268131  2441   344  1981          1    8  ...   NaN   \n",
       "2    1   16  NaN  7.0  167581   754   143  1995          1    3  ...   1.0   \n",
       "3    4   44  5.0  NaN  445071  5705   604  1980          1    3  ...   NaN   \n",
       "4    4   43  NaN  6.0  436161  5645   592  1958          1    3  ...   NaN   \n",
       "\n",
       "  GN1_OTHERS  GN2  GN2_OTHERS  GN3  GN3_OTHERS  GN4  GN4_OTHERS  GN5  \\\n",
       "0        NaN   99         NaN   99         NaN   99         NaN   99   \n",
       "1        NaN    1         NaN    2         NaN    2         NaN    2   \n",
       "2        NaN    2         NaN    2         NaN    2         NaN    2   \n",
       "3        NaN    2         NaN    2         NaN   99         NaN   99   \n",
       "4        NaN    1         NaN    1         NaN    1         NaN    1   \n",
       "\n",
       "   GN5_OTHERS  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  \n",
       "\n",
       "[5 rows x 1234 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating datasample to experiment much faster\n",
    "data_sample = data.iloc[:500].copy()\n",
    "data_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ```TabularDataset``` 0.0.1\n",
    "In this attempt we will just create a simple datatset class that takes in raw data and will split between: ```X Y``` and create seperate ```x_train, x_val, y_train y_val``` which will individually containm ```X1, X2, Y```.\n",
    "\n",
    "This class will also perform all pre-processing from removing and replacing NAs and perform LabelEncoding to both Categorical variables and our Dependent Variables: A class-map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# 1.\n",
    "class TabularBunch():\n",
    "    \"\"\"\n",
    "    \n",
    "    df: <pandas df>\n",
    "    categorical: <df[col]>: columns which represent all categorical (discrete) variables\n",
    "    \n",
    "    This class will turn all columns but categorical & dependent into continuous variables. IF there aren't any categorical (categorical==None) then we will treat all but dependent variables as continuous.\n",
    "    \n",
    "    NB: Perform some data analysis and exploration before calling this method. For later versions we will automate this full process.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, df, categorical=None, dependent=None, null_thresh=0., verbose=True):\n",
    "        super().__init__()\n",
    "        assert dependent # needs dependent variable to work\n",
    "        self.df = df.copy()\n",
    "        self.categorical = categorical\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        # cleaning df <OPTIONAL>: removing null values from certain threshold. \n",
    "        if null_thresh > 0.:\n",
    "            # this will clear our categorical list: as we have to clean some columns\n",
    "            self.categorical = self.purge_nulls_(null_thresh)\n",
    "            \n",
    "        # splitting X, y: Initial split | no cat/cont split\n",
    "        y = self.df[dependent] # all rows should have a target | dependent variable\n",
    "        X = self.df.drop(columns=dependent, axis=1)\n",
    "            \n",
    "        # creating classes\n",
    "        self.classes = set(y)\n",
    "        ### TO DO:\n",
    "        ### Create class index to class string mapping\n",
    "        ### This will help with any confusion and inference level interpretation\n",
    "\n",
    "        \n",
    "        # filling rest of null values: will perform just incase\n",
    "        X = self.fill_na_(X)\n",
    "            \n",
    "        # Splitting X into: x_cont, x_cat\n",
    "        # x_cont: continuous variables\n",
    "        # x_cat: categorical (discrete variables which will go into embeddings)\n",
    "        if categorical is not None: \n",
    "            self.X_cat = X[self.categorical].copy()\n",
    "            self.X_cont = X.drop(columns=self.categorical, axis=1).copy()\n",
    "            \n",
    "        else:\n",
    "            self.X_cat = None\n",
    "            self.X_cont = X.copy() # do nothing: we will use this placeholder for now\n",
    "            \n",
    "        # Turning our categorical dataset: X_cat into LabelEncodings\n",
    "        # This will turn cat1 -> 0, cat2 -> 1, for each cat within\n",
    "        # The category columns\n",
    "        self.labelencoding_()\n",
    "                \n",
    "        # Creating our embedding dictionaries\n",
    "        # this will help with forming nn.Embeddings\n",
    "        # and will also help with creating our datasets\n",
    "        if categorical:\n",
    "            self.emb_c = {n: len(col.cat.categories) for n,col in self.X_cat.items()}\n",
    "            self.emb_sz = [(c, min(50, (c+1)//2)) for _,c  in self.emb_c.items()]\n",
    "            self.emb_cols = self.categorical\n",
    "        \n",
    "        # our X, Y \n",
    "        # this will be used to feed into our dataset class\n",
    "        if self.X_cat is not None:\n",
    "            if len(self.X_cont.columns) == 0:\n",
    "                self.X = self.X_cat\n",
    "            else:\n",
    "                self.X = pd.concat([self.X_cat, self.X_cont])\n",
    "        else:\n",
    "            self.X = self.X_cont\n",
    "        self.Y = y\n",
    "        \n",
    "        # Clearning our attributes: Don't need to store everything\n",
    "        del self.X_cat\n",
    "        del self.X_cont\n",
    "        del self.categorical\n",
    "        del self.verbose\n",
    "        del self.df\n",
    "        \n",
    "        if verbose: print('Finished!')\n",
    "            \n",
    "    def purge_nulls_(self, null_thresh):\n",
    "        \"\"\"Will remove all columns with null values exceeding our threshold\"\"\"\n",
    "        if self.verbose: print(f'Performing null purge. Null threshold: {null_thresh}...')\n",
    "        \n",
    "        nt = int(len(self.df) * null_thresh)\n",
    "        \n",
    "        for col in self.df.columns:\n",
    "            if self.df[col].isnull().sum() > nt:\n",
    "                self.df.drop(col, axis=1, inplace=True)\n",
    "                \n",
    "        cols = list(self.df.columns)\n",
    "        categorical = self.categorical_left_(cols) # removing categories that are missing\n",
    "        return categorical\n",
    "                \n",
    "    def fill_na_(self, X):\n",
    "        \"\"\"Will perform a quick processing of NA values.\"\"\"\n",
    "        if self.verbose: print(f'Performing NaN Replacement...')\n",
    "        for col in X.columns:\n",
    "            if X.dtypes[col] == \"object\":\n",
    "                X[col] = X[col].fillna(\"NA\")\n",
    "            else:\n",
    "                X[col] = X[col].fillna(0)\n",
    "        return X\n",
    "        \n",
    "    \n",
    "    def labelencoding_(self):\n",
    "        if self.verbose: print(f'Performing label encoding operation. This may take a few seconds...')\n",
    "        if self.X_cat is not None:\n",
    "            for col in self.X_cat.columns:\n",
    "                le = LabelEncoder()\n",
    "                self.X_cat[col] = le.fit_transform(self.X_cat[col])\n",
    "                self.X_cat[col] = self.X_cat[col].astype('category')\n",
    "                \n",
    "    def categories_left_(self, cols):\n",
    "        \"\"\"\n",
    "        This method will return a list of all categorical columns that are left after purging our high-threshold NAs. This will simply update our list therefor not return anything.\n",
    "        \"\"\"\n",
    "        categorical_left = pd.Series()\n",
    "        for col in self.categorical:\n",
    "            mask = cols == col\n",
    "            masks = mask|masks\n",
    "        return categories_left\n",
    "    \n",
    "    def get_train_test_(self, test_size=0.1):\n",
    "        \"\"\"\n",
    "        This get_train_test_ method will take in a bunch object and append x_train, x_val, y_train, y_val using train_test_split from the scikit learn libray. \n",
    "\n",
    "        This will allow for everything to be kept in a single bunch object which will feed into the Learner class and Dataset class\n",
    "        \"\"\"\n",
    "        self.x_train, self.x_val, self.y_train, self.y_val = train_test_split(self.X,self.Y, test_size=test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# helper function to return categorical variables\n",
    "def get_categorical_(dependent, df):\n",
    "    \"\"\"\n",
    "    Helper function to return categorical variables\n",
    "    TO DO: Need to make this more dynamic, what if there are continuos variables? At the moment this function will turn all but the dependent variable as categorical variables\n",
    "    \"\"\"\n",
    "    return list(df.columns[df.columns != dependent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Defining our Dependent, Categorical, and Continuous Variables.\n",
    "# In this case, we don't have continuous: so will just feed dependent and cateorical\n",
    "dependent = 'is_female'\n",
    "categorical = get_categorical_(dependent, data_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing NaN Replacement...\n",
      "Performing label encoding operation. This may take a few seconds...\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "# 2. Building tabularbunch\n",
    "# Testing our class & methods\n",
    "# in production: We will first have to determine what is\n",
    "# categorical & continuos. \n",
    "# this will be part of the typical data exploration phase\n",
    "tabularbunch = TabularBunch(df=data_sample, categorical=categorical, dependent=dependent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #export\n",
    "# # 2. \n",
    "# def get_train_test_(bunch, test_size=0.1):\n",
    "#     \"\"\"\n",
    "#     This get_train_test_ function will take in a bunch object and append x_train, x_val, y_train, y_val using train_test_split from the scikit learn libray. \n",
    "    \n",
    "#     This will allow for everything to be kept in a single bunch object which will feed into the Learner class and Dataset class\n",
    "#     \"\"\"\n",
    "#     X, Y = bunch.X, bunch.Y\n",
    "#     bunch.x_train, bunch.x_val, bunch.y_train, bunch.y_val = train_test_split(X,Y, test_size=test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # splitting our data\n",
    "# # this will be appended to the bunch object\n",
    "# get_train_test_(tabularbunch, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting our data\n",
    "# We will simply call our split_test_train_ method \n",
    "# on our tabular bunch object\n",
    "tabularbunch.get_train_test_(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((450, 1233), (50, 1233))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking sizes to see if they match\n",
    "tabularbunch.x_train.shape, tabularbunch.x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((450,), (50,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabularbunch.y_train.shape, tabularbunch.y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# 2.\n",
    "# tabular dataset class\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, tabularbunch, ds_type='train'):\n",
    "        \"\"\"\n",
    "        This will be our main working dataset class. We will inherit from the Dataset class provided by PyTorch which will allow use to iterate through batches appropriateley when pushed to DataLoaders\n",
    "        \n",
    "        If there are both cat & cont variables, this will simply create a split X1, X2 respectively. \n",
    "        \"\"\"\n",
    "        if ds_type == 'train':\n",
    "            X = tabularbunch.x_train\n",
    "            Y = tabularbunch.y_train\n",
    "        else:\n",
    "            X = tabularbunch.x_val\n",
    "            Y = tabularbunch.y_val\n",
    "\n",
    "        # initial split\n",
    "        # we will split cat & cont variables | IF cont or cat doesn't exist\n",
    "        # this will just create a single X dataset\n",
    "        self.X1 = X.loc[:,tabularbunch.emb_cols].copy().values.astype(np.int64)\n",
    "        self.X2 = X.drop(columns=tabularbunch.emb_cols).copy().values.astype(np.float32)\n",
    "        self.y = Y.to_numpy().astype(np.float32) # vector \n",
    "        \n",
    "        # NORMALIZING CONT Dataset | if it exist\n",
    "        if self.X2.size:\n",
    "            self.X2 = (self.X2 - self.X2.mean()) / self.X2.std()\n",
    "                \n",
    "        # setting our dataset state\n",
    "        if self.X1.size and not self.X2.size: self.X_state = 'cat_only'\n",
    "        elif self.X2.size and not self.X1.size: self.X_state = 'cont_only'\n",
    "        else: self.X_state = 'both'\n",
    "        \n",
    "    \n",
    "    def __len__(self): return len(self.y)\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Will iterate through condition: If X2 is not empty we will return both X1 & X2, otherwise just X1\n",
    "        \"\"\"\n",
    "        if self.X_state == 'cat_only': return self.X1[idx], self.y[idx]\n",
    "        elif self.X_state == 'cont_only': return self.X2[idx], self.y[idx]\n",
    "        else: return self.X1[idx], self.X2[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing our train and test datasets\n",
    "# we will feed our tabularbunch object \n",
    "train_ds = TabularDataset(tabularbunch, ds_type='train')\n",
    "valid_ds = TabularDataset(tabularbunch, ds_type='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to grab train_ds and valid_ds in one grab\n",
    "def get_datasets_(tabularbunch):\n",
    "    \"\"\"\n",
    "    Will return train and valid datasets\n",
    "    \"\"\"\n",
    "    train_ds = TabularDataset(tabularbunch, ds_type='train')\n",
    "    valid_ds = TabularDataset(tabularbunch, ds_type='valid')\n",
    "    return train_ds, valid_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grabbing our train and valid ds using our helper function\n",
    "train_ds, valid_ds = get_datasets_(tabularbunch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have our train and valid datasets we will create\n",
    "# dataloaders using PyTorchs DataLoader class\n",
    "# We will have to feed it bs\n",
    "bs = 5\n",
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3, 19,  0, ...,  1,  0,  1],\n",
       "       [ 1,  9,  5, ...,  1,  2,  1],\n",
       "       [ 0,  2,  0, ...,  1,  3,  1],\n",
       "       ...,\n",
       "       [ 1,  8,  0, ...,  1,  2,  1],\n",
       "       [ 0,  4,  0, ...,  1,  0,  1],\n",
       "       [ 0,  3,  0, ...,  1,  5,  1]], dtype=int64)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how to quickly check the dataset\n",
    "train_dl.dataset.X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# 3.\n",
    "# A\n",
    "# Creating our DataBunch class which will create data objects that will \n",
    "# feed into our learner class \n",
    "# this will store everything regarding our data\n",
    "# and will make the entire process or creating a tabular dataloader \n",
    "# much easier.\n",
    "# simply put: this puts everything together in one place\n",
    "### V0.1.0 ### \n",
    "class TabularData():\n",
    "    def __init__(self, tabularbunch, test_size:float=0.1, bs:int=64, train_shuffle:bool=True,**kwargs):\n",
    "        \"\"\"\n",
    "        Tabular Data class will host everything associated with tabular data. This will be the main class that our Learner class will use to both train and test on.\n",
    "        \"\"\"\n",
    "        self.tabularbunch = tabularbunch \n",
    "        self.tabularbunch.get_train_test_(test_size=test_size)\n",
    "        \n",
    "        # grabbing our datasets\n",
    "        train_ds, valid_ds = self.get_datasets_()\n",
    "        \n",
    "        # setting our dataloaders\n",
    "        self.train_dl = DataLoader(train_ds, batch_size=bs, shuffle=train_shuffle, **kwargs)\n",
    "        self.valid_dl = DataLoader(valid_ds, batch_size=bs, **kwargs)\n",
    "        \n",
    "    def get_datasets_(self):\n",
    "        \"\"\"\n",
    "        retrieve test train split\n",
    "        \"\"\"\n",
    "        train_ds = TabularDataset(self.tabularbunch, ds_type='train')\n",
    "        valid_ds = TabularDataset(self.tabularbunch, ds_type='valid')\n",
    "        return train_ds, valid_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting our data with our TabularData function\n",
    "data = TabularData(tabularbunch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Workflow\n",
    "We will now experiment with several datasets and go through the workflow. Lastly, we will feed our ```TabularData``` object into our ```Learner``` object which will do all the training and inference processing. \n",
    "\n",
    "We will cover ```Learner``` in ```02``` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. ### \n",
    "# The first thing we will do is grab our raw data and perform some exploration\n",
    "# and any extra pre-processing. This can be from feature extraction\n",
    "# to clairvoyance augmentation\n",
    "df = pd.read_csv('./data/wids/train.csv', low_memory=False).iloc[:100] # grab first 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2. ###\n",
    "# Now we will simply grab variable names if they exist\n",
    "# these will be: Categorical variables, Continuous variables, Dependent variable\n",
    "# nb: Dependent is what we are either predicting or forecasting\n",
    "\n",
    "# this dataset does not contain any continuous variables. We will show this in the\n",
    "# next example\n",
    "dependent = 'is_female'\n",
    "categorical = get_categorical_(dependent, df) # custom functon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing NaN Replacement...\n",
      "Performing label encoding operation. This may take a few seconds...\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "### 3. ###\n",
    "# Creating our tabularbunch\n",
    "# This will be our core object which will perform some initial pre-processing \n",
    "# and will store embs for categorical. This will be fed into our TabularDataset\n",
    "tabularbunch = TabularBunch(df=df, categorical=categorical, dependent=dependent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4. ###\n",
    "# Creating our Data Object\n",
    "# This will be the main component to proccess the data in our Learner object\n",
    "data = TabularData(tabularbunch, bs=32, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export: V0.1.0 \n",
    "*Updated 12/22/2019*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted copernicusTabular_001.ipynb to exp\\nb_copernicusTabular.py\n"
     ]
    }
   ],
   "source": [
    "!python notebook2script.py copernicusTabular_001.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
